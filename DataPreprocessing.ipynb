{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "This document describes the data preprocessing steps used in the paper.\n",
    "* six gold standard datasets\n",
    "* six silver standard datasets\n",
    "* two large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## six gold standard datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file ='scRNA-seq/data/gold_standard/gold_counts_label/'\n",
    "c1=pd.read_csv(file+'gold_countsfile.csv')\n",
    "label1=pd.read_csv(file+'gold_label.csv')\n",
    "counts_list=c1.iloc[:,1].tolist()\n",
    "label_list=label1.iloc[:,1].tolist()\n",
    "filename=['Biase','deng','goolam','kolodziejczyk','pollen','yan']\n",
    "for i in range(len(filename)):\n",
    "    data=sc.read_csv(file+counts_list[i]).T\n",
    "    label=pd.read_csv(file+label_list[i])\n",
    "    print(label.iloc[0:5,-1])\n",
    "    data.obs['celltype']=pd.Categorical(label.iloc[:,-1])\n",
    "    data.var['dropouts'] = np.sum(data.to_df()==0,axis=0)/data.to_df().shape[0]*100\n",
    "    \n",
    "    print(f'***********************step1: gene/cell filtering')\n",
    "    data = data[:,data.var['dropouts'].values >10]\n",
    "    data = data[:,data.var['dropouts'].values <90]\n",
    "\n",
    "    print(f'***********************step2: normalization')\n",
    "    sc.pp.normalize_total(data, target_sum=1e4)\n",
    "    sc.pp.log1p(data)\n",
    "\n",
    "    print(f'***********************step3: selection of highly variable genes')\n",
    "    sc.pp.highly_variable_genes(data, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    data = data[:, data.var.highly_variable]\n",
    "\n",
    "    print(f'***********************step4: dimension reduction by PCA')\n",
    "    sc.pp.scale(data, max_value=10)\n",
    "    data.var['MT']=data.var_names.str.startswith('MT')\n",
    "    data.var['ercc'] = data.var_names.str.startswith('ERCC')  # annotate the group of mitochondrial genes as 'mt'\n",
    "    sc.pp.calculate_qc_metrics(data, qc_vars=['ercc'], percent_top=None, log1p=False, inplace=True)\n",
    "    data = data[:,~data.var['ercc']]\n",
    "    data=data[:,~data.var['MT']]\n",
    "    sc.tl.pca(data,svd_solver='arpack')\n",
    "    print(f'{counts_list[i]}: after processing: {data.shape}')\n",
    "    data.write(filename[i]+'_pca.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## six silver standard datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "file=['10X_PBMC.h5','human_kidney_counts.h5','Shekhar_mouse_retina_raw_data.h5',\n",
    "'CITE_CBMC_counts_top2000.h5','worm_neuron_cell.h5']\n",
    "for i in range(len(file)):\n",
    "    print(file[i])\n",
    "    data_mat = h5py.File(file[i])\n",
    "    data = sc.AnnData(np.array(data_mat['X']))\n",
    "    data.obs['label'] = np.array(data_mat['Y'])\n",
    "    print(f'***********************step1: gene/cell filtering')\n",
    "    sc.pp.filter_genes(data, min_counts=1)\n",
    "    sc.pp.filter_cells(data, min_counts=1)\n",
    "    \n",
    "    print(f'***********************step2: normalization')\n",
    "    sc.pp.normalize_per_cell(data)\n",
    "    sc.pp.log1p(data)\n",
    "    \n",
    "    print(f'***********************step3: selection of highly variable genes')\n",
    "    sc.pp.highly_variable_genes(data, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "    data = data[:, data.var.highly_variable]\n",
    "    print(f'{file[i]}: after processing: {data.shape}')\n",
    "    print(f'***********************step4: dimension reduction by PCA')\n",
    "    sc.pp.scale(data, max_value=10)\n",
    "    sc.tl.pca(data, svd_solver='arpack')\n",
    "    filename=file[i].split('.')[0]\n",
    "    data.write(filename+'.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAM FACS --- checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read('tabula-muris-senis-facs-official-raw-obj.h5ad')\n",
    "print(f'***********************step1: gene/cell filtering')\n",
    "sc.pp.filter_genes(adata,min_cells=3)\n",
    "sc.pp.filter_cells(adata,min_genes=250) \n",
    "sc.pp.calculate_qc_metrics(data, percent_top=None, log1p=False, inplace=True)\n",
    "sc.pp.filter_cells(adata,min_counts=5000)\n",
    "\n",
    "print(f'***********************step2: normalization')\n",
    "# sc.pp.normalize_total(adata,target_sum=1e4)\n",
    "sc.pp.normalize_per_cell(adata,counts_per_cell_after=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "print(f'***********************step3: selection of highly variable genes')\n",
    "sc.pp.highly_variable_genes(adata,min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "adata = adata[:, adata.var.highly_variable]\n",
    "\n",
    "print(f'***********************step4: dimension reduction by PCA')\n",
    "sc.pp.scale(adata,max_value=10)\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "adata.write('facs_pca.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## two large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse brain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '/public/home/zhengxq/nieyating/H/1.3m_scAIDE_labels.h5ad'\n",
    "data=sc.read('1.3m_scAIDE_labels.h5ad')\n",
    "data.obs['label']=pd.Categorical(data.obs['pred'].values.tolist())\n",
    "print(data.obs['label'])\n",
    "data.var_names_make_unique()\n",
    "print(f'***********************step1: gene/cell filtering')\n",
    "sc.pp.filter_cells(data, min_genes=200)\n",
    "sc.pp.filter_genes(data, min_cells=3)\n",
    "sc.pp.calculate_qc_metrics(data, percent_top=None, log1p=False, inplace=True)\n",
    "# data = data[data.obs.n_genes_by_counts < 2500, :]\n",
    "data = data[data.obs.pct_counts_mt < 5, :]\n",
    "\n",
    "print(f'***********************step2: normalization')\n",
    "sc.pp.normalize_total(data, target_sum=1e4)\n",
    "sc.pp.log1p(data)\n",
    "\n",
    "print(f'***********************step3: selection of highly variable genes')\n",
    "sc.pp.highly_variable_genes(data, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "data = data[:,data.var.highly_variable]\n",
    "\n",
    "print(f'***********************step4: dimension reduction by PCA')\n",
    "sc.pp.scale(data, max_value=10)\n",
    "sc.tl.pca(data)\n",
    "data.write('brain_pca.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /public/home/zhengxq/weinn/Clustering_scRNA/scRNA-seq/Cluster0906/guodata\n",
    "dat = sc.read('MCA_BatchRemoved_Merge_dge.h5ad')\n",
    "print(f'***********************step1: gene/cell filtering')\n",
    "sc.pp.filter_genes(dat, min_cells=3)\n",
    "sc.pp.filter_cells(dat, min_genes=100)\n",
    "\n",
    "print(f'***********************step2: normalization')\n",
    "sc.pp.normalize_total(dat, target_sum=1e4) \n",
    "sc.pp.log1p(dat)\n",
    "\n",
    "print(f'***********************step3: selection of highly variable genes')\n",
    "sc.pp.highly_variable_genes(dat, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "dat = dat[:, dat.var.highly_variable]\n",
    "\n",
    "print(f'***********************step4: dimension reduction by PCA')\n",
    "sc.pp.scale(dat, max_value=10)\n",
    "sc.tl.pca(dat, svd_solver='arpack')\n",
    "dat.write('MCA_processed.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "2bed7d32d79e9dd13b2aed7719fd38fc2ec9d35f087c458351b53f63f2d76222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
